{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJK-OF5a4bg9",
        "outputId": "42015651-6b8d-462c-feb5-22cdb1f6477a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import ast\n",
        "import json\n",
        "from collections import Counter\n",
        "from dateutil import parser\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "import random\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "pd.options.mode.chained_assignment = \"warn\"\n",
        "\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6kEivxaK4f4W"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/news_before_processing.csv',  sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhpBNL-1z6Gb"
      },
      "source": [
        "###Processing Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XVIiIoYKvwD"
      },
      "outputs": [],
      "source": [
        "#processing\n",
        "df = df.drop_duplicates()\n",
        "df = df.drop(df[df['tag'].apply(lambda x: x == '[]')].index)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "def get_tags(tag_string):\n",
        "    try:\n",
        "        tags_list = ast.literal_eval(tag_string)\n",
        "        if isinstance(tags_list, list):\n",
        "            if len(tags_list) == 1:\n",
        "                return tags_list[0]\n",
        "            else:\n",
        "                return tag_string\n",
        "    except:\n",
        "        return tag_string\n",
        "\n",
        "    if tag_string == '\"Болотное дело\"':\n",
        "        return 'Болотное дело'\n",
        "\n",
        "\n",
        "# первичная обработка тэгов\n",
        "df['tags_list'] = df['tag'].apply(get_tags)\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'^[\\r\\n\\s]+|[\\r\\n\\s]+$', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "df['tags_list'] = df['tags_list'].apply(clean_text)\n",
        "\n",
        "#считаем распространенность тэгов\n",
        "tags_list = []\n",
        "\n",
        "for cell in df['tags_list']:\n",
        "    if '[' in cell:\n",
        "        tags = [tag.strip().replace(\"'\", \"\") for tag in cell[1:-1].split(',')]\n",
        "        for tag in tags:\n",
        "            tags_list.append(tag.strip())\n",
        "    else:\n",
        "        tags_list.append(cell.strip())\n",
        "\n",
        "tag_counter = Counter(tags_list)\n",
        "\n",
        "#вторичная обработка тэгов (выбор одного популярного тэга, если представлено несколько)\n",
        "def select_most_popular_tag(text):\n",
        "    if re.match(r\"\\['.*'\\]$\", text):\n",
        "        tags = re.findall(r\"'([^']+)'\", text)\n",
        "        valid_tags = [tag.strip() for tag in tags if tag_counter.get(tag.strip())]\n",
        "        return max(valid_tags, key=tag_counter.get)\n",
        "    else:\n",
        "        return text\n",
        "\n",
        "df['most_popular_tag'] = df['tags_list'].apply(select_most_popular_tag)\n",
        "\n",
        "df.drop('tags_list', axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2jNDswTiDE-"
      },
      "outputs": [],
      "source": [
        "#Удаление строк, в которых содержится очень редкий тэг\n",
        "most_popular_tag_counter = Counter(df['most_popular_tag'])\n",
        "tags_to_remove = [tag for tag, count in most_popular_tag_counter.items() if count < 100]\n",
        "df = df[~df['most_popular_tag'].isin(tags_to_remove)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_wXLuecmRsX",
        "outputId": "7fb9d660-4886-40db-f85a-f57f3cb85a1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество неправильных дат: 0\n"
          ]
        }
      ],
      "source": [
        "#преобразование даты\n",
        "df = df[df['date and time'] != '01.01.0001, 00:00']\n",
        "\n",
        "month_dict = {\n",
        "    'января': '01','февраля': '02','марта': '03','апреля': '04','мая': '05',\n",
        "    'июня': '06','июля': '07','августа': '08','сентября': '09','октября': '10',\n",
        "    'ноября': '11','декабря': '12'\n",
        "}\n",
        "\n",
        "df['date and time'].replace(month_dict, regex=True, inplace=True)\n",
        "\n",
        "df['date and time'] = df['date and time'].apply(lambda x: parser.parse(x, fuzzy=True) if pd.notna(x) else x)\n",
        "\n",
        "df['date and time'] = pd.to_datetime(df['date and time'], errors='coerce')\n",
        "\n",
        "print(\"Количество неправильных дат:\", df['date and time'].isna().sum())\n",
        "\n",
        "df = df[df['date and time'].dt.year >= 2001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmTHdZ2Mo5CM",
        "outputId": "afe70c79-5496-42e8-de91-9de6410ce37d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [01:50<00:00, 55.31s/it]\n"
          ]
        }
      ],
      "source": [
        "#преобразование title, text\n",
        "def clean_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'^[\\r\\n\\s]+|[\\r\\n\\s]+$', '', text)\n",
        "    return text.strip()\n",
        "\n",
        "for col in tqdm(['title', 'text']):\n",
        "    df[col] = df[col].apply(clean_text)\n",
        "\n",
        "df = df[df['text'].str.strip() != '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRTGdXfsqfUz",
        "outputId": "fbf7eac4-90c7-440c-e7a6-7c04302dafa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1271195 entries, 0 to 1460901\n",
            "Data columns (total 6 columns):\n",
            " #   Column            Non-Null Count    Dtype         \n",
            "---  ------            --------------    -----         \n",
            " 0   url               1271195 non-null  object        \n",
            " 1   date and time     1271195 non-null  datetime64[ns]\n",
            " 2   tag               1271195 non-null  object        \n",
            " 3   title             1271195 non-null  object        \n",
            " 4   text              1271195 non-null  object        \n",
            " 5   most_popular_tag  1271195 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(5)\n",
            "memory usage: 67.9+ MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQgBiBQe6Ndf"
      },
      "outputs": [],
      "source": [
        "df.to_csv('news_after_processing.csv', index=False, sep=';')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDXm-Hol1ZBQ"
      },
      "source": [
        "###Processing text and Base Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UJkWzGQ7ljF"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/news_after_processing.csv',  sep=';')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top = df['most_popular_tag'].value_counts()[:50].index.tolist()\n",
        "filter = pd.DataFrame(top)\n",
        "df['flag'] = df['most_popular_tag'].apply(lambda x: x in top)\n",
        "filter_df = df[df.flag == True]\n",
        "df_sample = filter_df.sample(n=50000, random_state=42).drop('flag', axis=1)"
      ],
      "metadata": {
        "id": "0gEmiUx_l5oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/data_50k_preproc.csv',  sep=',')"
      ],
      "metadata": {
        "id": "jFuhmslcl5qg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop('Unnamed: 0', axis=1)"
      ],
      "metadata": {
        "id": "Kbd6cKXuHv1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwTbj7eFH_K9",
        "outputId": "ba7dab04-808b-48b3-8e2c-549c1b3e62cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['url', 'date and time', 'tag', 'title', 'text', 'most_popular_tag',\n",
              "       'preprocessed_text'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "mystem = Mystem()\n",
        "\n",
        "# Функция для лемматизации текста на русском\n",
        "def lemmatize_text_russian(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'^[\\r\\n\\s]+|[\\r\\n\\s]+$', '', text)\n",
        "    text = re.sub(r'\\[|\\]', '', text)\n",
        "    lemmatized_tokens = mystem.lemmatize(text.lower())\n",
        "    return \" \".join([token for token in lemmatized_tokens if token.strip()])\n",
        "\n",
        "# Пример предварительной обработки текста на русском с лемматизацией\n",
        "df_sample_processed_russian = [lemmatize_text_russian(text) for text in tqdm(df_sample['text'])]\n",
        "# lemmatize_text_russian(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ozw8JcWckz_K",
        "outputId": "b0be029c-04c9-4fcb-a6f9-ebba8cf28b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50000/50000 [08:16<00:00, 100.65it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_sample_processed_russian)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-XK8tx6koPBV",
        "outputId": "778a7032-d597-4503-d3dd-6e426ad7299d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample['preprocessed_text'] = df_sample_processed_russian"
      ],
      "metadata": {
        "id": "FcJrtZGau5CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[2:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "PDdAd4wQTGID",
        "outputId": "9bbe7810-4467-4686-b5a7-5df7630eaa73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    url        date and time           tag  \\\n",
              "2  https://www.kommersant.ru/doc/995727  2006-11-15 18:59:00  Происшествия   \n",
              "\n",
              "                                      title  \\\n",
              "2  От \"Пулково\" требуют более 32 млн рублей   \n",
              "\n",
              "                                                                                                                                                      text  \\\n",
              "2  Пострадавшие в результате катастрофы российского пассажирского самолета Ту-154 под Донецком подали иск в Тушинский суд Москвы к авиакомпании \"Пулково\".   \n",
              "\n",
              "  most_popular_tag  \\\n",
              "2     Происшествия   \n",
              "\n",
              "                                                                                                                                          preprocessed_text  \n",
              "2  пострадать в результат катастрофа российский пассажирский самолет тот - 154 под донецк подавать иск в тушинский суд москва к авиакомпания  \" пулково \" .  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-538db475-0eea-476e-aa02-e0ff8b9d4f4d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>date and time</th>\n",
              "      <th>tag</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>most_popular_tag</th>\n",
              "      <th>preprocessed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://www.kommersant.ru/doc/995727</td>\n",
              "      <td>2006-11-15 18:59:00</td>\n",
              "      <td>Происшествия</td>\n",
              "      <td>От \"Пулково\" требуют более 32 млн рублей</td>\n",
              "      <td>Пострадавшие в результате катастрофы российского пассажирского самолета Ту-154 под Донецком подали иск в Тушинский суд Москвы к авиакомпании \"Пулково\".</td>\n",
              "      <td>Происшествия</td>\n",
              "      <td>пострадать в результат катастрофа российский пассажирский самолет тот - 154 под донецк подавать иск в тушинский суд москва к авиакомпания  \" пулково \" .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-538db475-0eea-476e-aa02-e0ff8b9d4f4d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-538db475-0eea-476e-aa02-e0ff8b9d4f4d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-538db475-0eea-476e-aa02-e0ff8b9d4f4d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_sample.to_csv('data_50k_preproc.csv')"
      ],
      "metadata": {
        "id": "ISNzGtn0u-iw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/preprocessed_text_50000.csv',  sep=';')"
      ],
      "metadata": {
        "id": "ZfiGdpLns2H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "U-f07JQ5qphm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Yh8WhepmGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72f9109d-21be-4fad-b51b-bba29919d07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 2 columns):\n",
            " #   Column            Non-Null Count  Dtype \n",
            "---  ------            --------------  ----- \n",
            " 0   processed_texts   50000 non-null  object\n",
            " 1   most_popular_tag  50000 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 781.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7vshorC7gJv"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.processed_texts, df.most_popular_tag, test_size=0.2, random_state=42)\n",
        "x_train\n",
        "data = pd.DataFrame(columns=['Parameters', 'Accuracy', 'Precision', 'Recall', 'F1-score'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_mlb = label_encoder.fit_transform(y_train)\n",
        "y_test_mlb = label_encoder.transform(y_test)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer(ngram_range=(1, 2), max_features=15000)),\n",
        "        ('clf', LogisticRegression(max_iter = 10000, multi_class='ovr', solver='liblinear'))\n",
        "    ])\n",
        "\n",
        "ran = np.arange(len(x_train))\n",
        "inds = np.array_split(ran, 3)\n",
        "\n",
        "for chunk in tqdm(inds):\n",
        "        # chunk_with_random = np.concatenate((chunk, np.array(random.sample(list(ran), k=10))))\n",
        "    pipeline.fit(np.array(x_train)[chunk], y_train_mlb[chunk])"
      ],
      "metadata": {
        "id": "RB25ncw_flwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import torch.nn.functional as F\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_mlb = label_encoder.fit_transform(y_train)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train_mlb, test_size=0.2, random_state=42)\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "1hCInOvXfJhI",
        "outputId": "c194e61f-0a1f-44f6-d260-5189c520154a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "module functions cannot set METH_CLASS or METH_STATIC",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4b4315203690>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    235\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: module functions cannot set METH_CLASS or METH_STATIC"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ckJIDUXtfUpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nzhGCtmffUNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IEjqvtCPfJmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Cdb5ycYfJow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_mlb = label_encoder.fit_transform(y_train)\n",
        "y_test_mlb = label_encoder.transform(y_test)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "        ('vectorizer', TfidfVectorizer(ngram_range=(1, 2), max_features=15000)),\n",
        "        ('clf', LogisticRegression(max_iter = 10000, multi_class='ovr', solver='liblinear'))\n",
        "    ])\n",
        "\n",
        "ran = np.arange(len(x_train))\n",
        "inds = np.array_split(ran, 3)\n",
        "\n",
        "for chunk in tqdm(inds):\n",
        "        # chunk_with_random = np.concatenate((chunk, np.array(random.sample(list(ran), k=10))))\n",
        "    pipeline.fit(np.array(x_train)[chunk], y_train_mlb[chunk])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "BOIqHqp4IWoC",
        "outputId": "2ec03617-d02f-48c4-d991-6c1a4861c2d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 1/3 [00:22<00:45, 22.86s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-16d59deb5a17>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# chunk_with_random = np.concatenate((chunk, np.array(random.sample(list(ran), k=10))))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_mlb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \"\"\"\n\u001b[1;32m    400\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    357\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# Fit or load from cache the current transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   2131\u001b[0m             \u001b[0msublinear_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublinear_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m         )\n\u001b[0;32m-> 2133\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1386\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m         \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixed_vocabulary_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1273\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \"\"\"\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(label_encoder, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzUJt4YJRIXj",
        "outputId": "254326a2-ea49-4ff9-876d-b8b243c01a8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "SIMJWWZaQvoa",
        "outputId": "0990a71f-cd44-42b6-f295-d376485b1135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vectorizer',\n",
              "                 TfidfVectorizer(max_features=15000, ngram_range=(1, 2))),\n",
              "                ('clf',\n",
              "                 LogisticRegression(max_iter=10000, multi_class='ovr',\n",
              "                                    solver='liblinear'))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(max_features=15000, ngram_range=(1, 2))),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 LogisticRegression(max_iter=10000, multi_class=&#x27;ovr&#x27;,\n",
              "                                    solver=&#x27;liblinear&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
              "                 TfidfVectorizer(max_features=15000, ngram_range=(1, 2))),\n",
              "                (&#x27;clf&#x27;,\n",
              "                 LogisticRegression(max_iter=10000, multi_class=&#x27;ovr&#x27;,\n",
              "                                    solver=&#x27;liblinear&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=15000, ngram_range=(1, 2))</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=10000, multi_class=&#x27;ovr&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(pipeline, 'base_logreg_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfu1-3FzJaA2",
        "outputId": "758dcfa5-6ece-407b-933a-30371cbe5644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['base_logreg_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZK0AH3O5IWqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D0Xf2slEIWsy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kkQ86Mz4IWvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pymystem3 import Mystem\n",
        "\n",
        "mystem = Mystem()\n",
        "\n",
        "# Функция для лемматизации текста на русском\n",
        "def lemmatize_text_russian(text):\n",
        "    lemmatized_tokens = mystem.lemmatize(text.lower())\n",
        "    return \" \".join([token for token in lemmatized_tokens if token.strip()])\n",
        "\n",
        "# Пример предварительной обработки текста на русском с лемматизацией\n",
        "x_train_processed_russian = [lemmatize_text_russian(text) for text in x_train]\n",
        "x_test_processed_russian = [lemmatize_text_russian(text) for text in x_test]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9Q6LqTkjI4u",
        "outputId": "2db995fd-7f4f-4532-df51-18e6f98dcc61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Installing mystem to /root/.local/bin/mystem from http://download.cdn.yandex.net/mystem/mystem-3.1-linux-64bit.tar.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_mlb = label_encoder.fit_transform(y_train)\n",
        "y_test_mlb = label_encoder.transform(y_test)\n",
        "\n",
        "def pipline_mod(vect, clasif, data):\n",
        "    pipeline = Pipeline([\n",
        "        ('vectorizer', vect),\n",
        "        ('clf', clasif)\n",
        "    ])\n",
        "\n",
        "    ran = np.arange(len(x_train_processed_russian))\n",
        "    inds = np.array_split(ran, 3)\n",
        "\n",
        "    for chunk in tqdm(inds):\n",
        "        # chunk_with_random = np.concatenate((chunk, np.array(random.sample(list(ran), k=10))))\n",
        "        pipeline.fit(np.array(x_train_processed_russian)[chunk], y_train_mlb[chunk])\n",
        "\n",
        "    predicted_labels = pipeline.predict(x_test_processed_russian)\n",
        "\n",
        "    predicted_labels = pipeline.predict(x_test_processed_russian)\n",
        "    accuracy = accuracy_score(y_test_mlb, predicted_labels)\n",
        "    precision = precision_score(y_test_mlb, predicted_labels, average='weighted')\n",
        "    recall = recall_score(y_test_mlb, predicted_labels, average='weighted')\n",
        "    f1 = f1_score(y_test_mlb, predicted_labels, average='weighted')\n",
        "\n",
        "    params = str(pipeline.named_steps['clf']) + ' ' + str(pipeline.named_steps['clf'].get_params()) + ' ' + str(pipeline.named_steps['vectorizer'].get_params())\n",
        "    data = data.append({'Parameters': params, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}, ignore_index=True)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "bQYatJXnxfJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 2), max_features=15000)\n",
        "clfs = [SGDClassifier(max_iter=100000, loss='log_loss', random_state=42),\n",
        "        SGDClassifier(max_iter=100000, loss='squared_error', random_state=42)]\n",
        "for clf in clfs:\n",
        "  data = pipline_mod(vect, clf, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mthcGxwx7md",
        "outputId": "72bb62b1-acc5-42b8-fb46-c6d9bc0102c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:58<00:00, 19.60s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [01:09<00:00, 23.02s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 1), max_features=15000)\n",
        "data = pipline_mod(vect, RandomForestClassifier(n_estimators=100, random_state=42), data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ8EybiLzb1s",
        "outputId": "82e92d4a-8a7f-45c8-f5de-134e9d41c21b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [02:27<00:00, 49.11s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 1), max_features=15000)\n",
        "data = pipline_mod(vect, SVC(random_state=42), data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEFSYfa9Df0u",
        "outputId": "d73dbd6b-637d-436a-c0fb-e47dca009388"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [32:22<00:00, 647.48s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 1), max_features=15000)\n",
        "clfs = [SGDClassifier(max_iter=100000, loss='log_loss', random_state=42),\n",
        "        SGDClassifier(max_iter=100000, loss='squared_error', random_state=42),\n",
        "        LogisticRegression(max_iter = 100000, multi_class='ovr', solver='liblinear'),\n",
        "        LogisticRegression(max_iter = 10000, multi_class='ovr', solver='liblinear')]\n",
        "for clf in clfs:\n",
        "  data = pipline_mod(vect, clf, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRadkxuyJDGs",
        "outputId": "c56db084-ddeb-4831-bc00-7340aa79b925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [00:30<00:00, 10.19s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [00:44<00:00, 14.87s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [01:19<00:00, 26.34s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [01:20<00:00, 26.80s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 1), max_features=15000)\n",
        "data = pipline_mod(vect, SVC(random_state=42), data)"
      ],
      "metadata": {
        "id": "QCMmYzpVOOOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 2), max_features=15000)\n",
        "clfs = [xgb.XGBClassifier(random_state=42),\n",
        "        LogisticRegression(max_iter = 10000, multi_class='ovr', solver='liblinear')]\n",
        "for clf in clfs:\n",
        "  data = pipline_mod(vect, clf, data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xylTQYCrum7v",
        "outputId": "71486361-96cf-48d7-cf90-83258160fa07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [1:00:57<00:00, 1219.01s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [01:42<00:00, 34.12s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vects = [\n",
        "         TfidfVectorizer(ngram_range=(1, 1), max_features=25000),\n",
        "         TfidfVectorizer(ngram_range=(1, 2), max_features=15000),\n",
        "         TfidfVectorizer(ngram_range=(2, 2), max_features=15000)]\n",
        "\n",
        "for vect in vects:\n",
        "  data = pipline_mod(vect, SVC(random_state=42), data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RIxGNMBOOR4",
        "outputId": "cdda91c8-40c6-408b-82c7-f00025d0fd3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3/3 [34:10<00:00, 683.55s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [35:15<00:00, 705.15s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "100%|██████████| 3/3 [14:09<00:00, 283.26s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vect = TfidfVectorizer(ngram_range=(1, 2), max_features=15000)\n",
        "clfs = [LGBMClassifier(random_state=42)]\n",
        "for clf in clfs:\n",
        "  data = pipline_mod(vect, clf, data)"
      ],
      "metadata": {
        "id": "e_yk_Z6VAehl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3ZMLYHFbJIwu",
        "outputId": "1184746e-3ec6-45cf-c506-f820a6cf94f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Parameters  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              RandomForestClassifier(random_state=42) {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              RandomForestClassifier(random_state=42) {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     SGDClassifier(loss='log_loss', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'log_loss', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           SGDClassifier(loss='squared_error', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_error', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     SGDClassifier(loss='log_loss', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'log_loss', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "6                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           SGDClassifier(loss='squared_error', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_error', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       LogisticRegression(max_iter=100000, multi_class='ovr', solver='liblinear') {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100000, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         LogisticRegression(max_iter=10000, multi_class='ovr', solver='liblinear') {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 10000, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 25000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "11                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (2, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "13  XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, feature_types=None,\\n              gamma=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=None, max_bin=None,\\n              max_cat_threshold=None, max_cat_to_onehot=None,\\n              max_delta_step=None, max_depth=None, max_leaves=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              multi_strategy=None, n_estimators=None, n_jobs=None,\\n              num_parallel_tree=None, objective='multi:softprob', ...) {'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        LogisticRegression(max_iter=10000, multi_class='ovr', solver='liblinear') {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 10000, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "15                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              LGBMClassifier(random_state=42) {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}   \n",
              "\n",
              "    Accuracy  Precision  Recall  F1-score  \n",
              "0     0.5141   0.565953  0.5141  0.454871  \n",
              "1     0.4448   0.507645  0.4448  0.388758  \n",
              "2     0.5816   0.609529  0.5816  0.537953  \n",
              "3     0.6080   0.604146  0.6080  0.557627  \n",
              "4     0.6349   0.600102  0.6349  0.595787  \n",
              "5     0.6057   0.583553  0.6057  0.553933  \n",
              "6     0.6231   0.590221  0.6231  0.585140  \n",
              "7     0.6181   0.610880  0.6181  0.569433  \n",
              "8     0.6181   0.610880  0.6181  0.569433  \n",
              "9     0.6186   0.611694  0.6186  0.570238  \n",
              "10    0.6154   0.607196  0.6154  0.566837  \n",
              "11    0.6213   0.614699  0.6213  0.573307  \n",
              "12    0.5186   0.588848  0.5186  0.475061  \n",
              "13    0.6439   0.643514  0.6439  0.630911  \n",
              "14    0.6194   0.608713  0.6194  0.570969  \n",
              "15    0.1874   0.083766  0.1874  0.088965  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26b55d02-df61-40ae-9d03-f2b3e0c55a18\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parameters</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RandomForestClassifier(random_state=42) {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.5141</td>\n",
              "      <td>0.565953</td>\n",
              "      <td>0.5141</td>\n",
              "      <td>0.454871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.4448</td>\n",
              "      <td>0.507645</td>\n",
              "      <td>0.4448</td>\n",
              "      <td>0.388758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RandomForestClassifier(random_state=42) {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.5816</td>\n",
              "      <td>0.609529</td>\n",
              "      <td>0.5816</td>\n",
              "      <td>0.537953</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SGDClassifier(loss='log_loss', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'log_loss', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6080</td>\n",
              "      <td>0.604146</td>\n",
              "      <td>0.6080</td>\n",
              "      <td>0.557627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SGDClassifier(loss='squared_error', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_error', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6349</td>\n",
              "      <td>0.600102</td>\n",
              "      <td>0.6349</td>\n",
              "      <td>0.595787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SGDClassifier(loss='log_loss', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'log_loss', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>0.583553</td>\n",
              "      <td>0.6057</td>\n",
              "      <td>0.553933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SGDClassifier(loss='squared_error', max_iter=100000, random_state=42) {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.0, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'squared_error', 'max_iter': 100000, 'n_iter_no_change': 5, 'n_jobs': None, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6231</td>\n",
              "      <td>0.590221</td>\n",
              "      <td>0.6231</td>\n",
              "      <td>0.585140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LogisticRegression(max_iter=100000, multi_class='ovr', solver='liblinear') {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100000, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.610880</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.569433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression(max_iter=10000, multi_class='ovr', solver='liblinear') {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 10000, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.610880</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.569433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.611694</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.570238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 25000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6154</td>\n",
              "      <td>0.607196</td>\n",
              "      <td>0.6154</td>\n",
              "      <td>0.566837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6213</td>\n",
              "      <td>0.614699</td>\n",
              "      <td>0.6213</td>\n",
              "      <td>0.573307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (2, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.5186</td>\n",
              "      <td>0.588848</td>\n",
              "      <td>0.5186</td>\n",
              "      <td>0.475061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, feature_types=None,\\n              gamma=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=None, max_bin=None,\\n              max_cat_threshold=None, max_cat_to_onehot=None,\\n              max_delta_step=None, max_depth=None, max_leaves=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              multi_strategy=None, n_estimators=None, n_jobs=None,\\n              num_parallel_tree=None, objective='multi:softprob', ...) {'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6439</td>\n",
              "      <td>0.643514</td>\n",
              "      <td>0.6439</td>\n",
              "      <td>0.630911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LogisticRegression(max_iter=10000, multi_class='ovr', solver='liblinear') {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 10000, 'multi_class': 'ovr', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.608713</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.570969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>LGBMClassifier(random_state=42) {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': None, 'num_leaves': 31, 'objective': None, 'random_state': 42, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': &lt;class 'numpy.float64'&gt;, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}</td>\n",
              "      <td>0.1874</td>\n",
              "      <td>0.083766</td>\n",
              "      <td>0.1874</td>\n",
              "      <td>0.088965</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26b55d02-df61-40ae-9d03-f2b3e0c55a18')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-26b55d02-df61-40ae-9d03-f2b3e0c55a18 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-26b55d02-df61-40ae-9d03-f2b3e0c55a18');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-07082c63-830c-4c16-9efd-b9dfb0c31909\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-07082c63-830c-4c16-9efd-b9dfb0c31909')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-07082c63-830c-4c16-9efd-b9dfb0c31909 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 16,\n  \"fields\": [\n    {\n      \"column\": \"Parameters\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"SVC(random_state=42) {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}\",\n          \"XGBClassifier(base_score=None, booster=None, callbacks=None,\\n              colsample_bylevel=None, colsample_bynode=None,\\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\\n              enable_categorical=False, eval_metric=None, feature_types=None,\\n              gamma=None, grow_policy=None, importance_type=None,\\n              interaction_constraints=None, learning_rate=None, max_bin=None,\\n              max_cat_threshold=None, max_cat_to_onehot=None,\\n              max_delta_step=None, max_depth=None, max_leaves=None,\\n              min_child_weight=None, missing=nan, monotone_constraints=None,\\n              multi_strategy=None, n_estimators=None, n_jobs=None,\\n              num_parallel_tree=None, objective='multi:softprob', ...) {'objective': 'multi:softprob', 'base_score': None, 'booster': None, 'callbacks': None, 'colsample_bylevel': None, 'colsample_bynode': None, 'colsample_bytree': None, 'device': None, 'early_stopping_rounds': None, 'enable_categorical': False, 'eval_metric': None, 'feature_types': None, 'gamma': None, 'grow_policy': None, 'importance_type': None, 'interaction_constraints': None, 'learning_rate': None, 'max_bin': None, 'max_cat_threshold': None, 'max_cat_to_onehot': None, 'max_delta_step': None, 'max_depth': None, 'max_leaves': None, 'min_child_weight': None, 'missing': nan, 'monotone_constraints': None, 'multi_strategy': None, 'n_estimators': None, 'n_jobs': None, 'num_parallel_tree': None, 'random_state': 42, 'reg_alpha': None, 'reg_lambda': None, 'sampling_method': None, 'scale_pos_weight': None, 'subsample': None, 'tree_method': None, 'validate_parameters': None, 'verbosity': None} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 2), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}\",\n          \"RandomForestClassifier(random_state=42) {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False} {'analyzer': 'word', 'binary': False, 'decode_error': 'strict', 'dtype': <class 'numpy.float64'>, 'encoding': 'utf-8', 'input': 'content', 'lowercase': True, 'max_df': 1.0, 'max_features': 15000, 'min_df': 1, 'ngram_range': (1, 1), 'norm': 'l2', 'preprocessor': None, 'smooth_idf': True, 'stop_words': None, 'strip_accents': None, 'sublinear_tf': False, 'token_pattern': '(?u)\\\\\\\\b\\\\\\\\w\\\\\\\\w+\\\\\\\\b', 'tokenizer': None, 'use_idf': True, 'vocabulary': None}\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1146457667484209,\n        \"min\": 0.1874,\n        \"max\": 0.6439,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6154,\n          0.5186,\n          0.5141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13162798047228016,\n        \"min\": 0.08376603765170955,\n        \"max\": 0.6435141735937916,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6071958508703085,\n          0.5888483916255315,\n          0.5659531663067925\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1146457667484209,\n        \"min\": 0.1874,\n        \"max\": 0.6439,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.6154,\n          0.5186,\n          0.5141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F1-score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12895467232294933,\n        \"min\": 0.08896480415913102,\n        \"max\": 0.6309106206023826,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.5668371576300641,\n          0.47506133173977105,\n          0.45487060173399785\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.to_excel('data.xlsx')"
      ],
      "metadata": {
        "id": "_nNxDEnuum1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Others"
      ],
      "metadata": {
        "id": "lObpqo6m-iWk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54JmZJQh6G1s"
      },
      "outputs": [],
      "source": [
        "# SGDClassifier и fasttext\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_mlb = label_encoder.fit_transform(y_train)\n",
        "y_test_mlb = label_encoder.transform(y_test)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('fasttext', FastTextVectorizer()),\n",
        "    ('clf', SGDClassifier(max_iter=1000, loss='log'))\n",
        "])\n",
        "\n",
        "ran = np.arange(len(x_train))\n",
        "inds = np.array_split(ran, 30)\n",
        "\n",
        "for chunk in tqdm(inds):\n",
        "    chunk_with_random = np.concatenate((chunk, np.array(random.sample(list(ran), k=1000))))\n",
        "    pipeline.fit(np.array(x_train)[chunk_with_random], y_train_mlb[chunk_with_random])\n",
        "\n",
        "predicted_labels = pipeline.predict(x_test)\n",
        "\n",
        "predicted_labels = pipeline.predict(x_test)\n",
        "accuracy = accuracy_score(y_test_mlb, predicted_labels)\n",
        "precision = precision_score(y_test_mlb, predicted_labels, average='weighted')\n",
        "recall = recall_score(y_test_mlb, predicted_labels, average='weighted')\n",
        "f1 = f1_score(y_test_mlb, predicted_labels, average='weighted')\n",
        "\n",
        "params = str(pipeline.named_steps['tfidf'].get_params()) + str(pipeline.named_steps['clf'].get_params())\n",
        "data = data.append({'Parameters': params, 'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1-score': f1}, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjlnpV8RDj-C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNEs9QrUihQP"
      },
      "outputs": [],
      "source": [
        "#Вариант предобработки текста\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Zа-яА-ЯёЁ\\s]', '', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('russian'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Лемматизация\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    preprocessed_text = ' '.join(tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "\n",
        "df['preprocessed_text'] = df['text'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DL\n"
      ],
      "metadata": {
        "id": "Ah3-_cZSlQKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('drive/MyDrive/Colab Notebooks/preprocessed_text_50000.csv',  sep=';')"
      ],
      "metadata": {
        "id": "xJ1f_UNilRyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(df.processed_texts, df.most_popular_tag, test_size=0.2, random_state=42)\n",
        "x_train\n",
        "data = pd.DataFrame(columns=['Parameters', 'Accuracy', 'Precision', 'Recall', 'F1-score'])"
      ],
      "metadata": {
        "id": "qR7R0kn3lR0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install fasttext\n",
        "\n",
        "import fasttext\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import os"
      ],
      "metadata": {
        "id": "YWehccQIlR23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_mlb = label_encoder.fit_transform(y_train)\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train_mlb, test_size=0.2, random_state=42)\n",
        "\n",
        "def prepare_fasttext_data(x, y, file_path):\n",
        "    with open(file_path, 'w') as f:\n",
        "        for text, label in zip(x, y):\n",
        "            f.write(f\"__label__{label} {text}\\n\")\n",
        "\n",
        "prepare_fasttext_data(x_train, y_train, 'train.txt')\n",
        "prepare_fasttext_data(x_val, y_val, 'val.txt')"
      ],
      "metadata": {
        "id": "f0p-m0hzl3h5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fasttext(model, x, y):\n",
        "    y_pred = []\n",
        "    for text in x:\n",
        "        label = model.predict(text)[0][0]\n",
        "        y_pred.append(int(label.replace(\"__label__\", \"\")))\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred, average='weighted')\n",
        "    return accuracy, f1\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model = fasttext.train_supervised(input='train.txt', epoch=epoch+1, lr=1.0, wordNgrams=2, verbose=2, minCount=1)\n",
        "\n",
        "    val_accuracy, val_f1 = evaluate_fasttext(model, x_val, y_val)\n",
        "    print(f\"Epoch: {epoch+1}, Validation Accuracy: {val_accuracy}, Validation F1 Score: {val_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTmDhbkCm68s",
        "outputId": "9c93dd2e-c278-4caa-be1f-3ae3242d47db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Validation Accuracy: 0.5785, Validation F1 Score: 0.5153227861303956\n",
            "Epoch: 2, Validation Accuracy: 0.67475, Validation F1 Score: 0.6523073784227519\n",
            "Epoch: 3, Validation Accuracy: 0.69375, Validation F1 Score: 0.6783723746787979\n",
            "Epoch: 4, Validation Accuracy: 0.695875, Validation F1 Score: 0.6837017569681205\n",
            "Epoch: 5, Validation Accuracy: 0.696375, Validation F1 Score: 0.6866987780013901\n",
            "Epoch: 6, Validation Accuracy: 0.697125, Validation F1 Score: 0.689524265457651\n",
            "Epoch: 7, Validation Accuracy: 0.696375, Validation F1 Score: 0.6899482694895099\n",
            "Epoch: 8, Validation Accuracy: 0.6955, Validation F1 Score: 0.6898448313304136\n",
            "Epoch: 9, Validation Accuracy: 0.696125, Validation F1 Score: 0.690593486374898\n",
            "Epoch: 10, Validation Accuracy: 0.696, Validation F1 Score: 0.6905138847266203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_mlb = label_encoder.transform(y_test)\n",
        "prepare_fasttext_data(x_test, y_test_mlb, 'test.txt')\n",
        "test_accuracy, test_f1 = evaluate_fasttext(model, x_test, y_test_mlb)\n",
        "print(f\"Final Test Accuracy: {test_accuracy}\")\n",
        "print(f\"Final Test F1 Score: {test_f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df32V5yRngHg",
        "outputId": "e9837cd8-9a48-4dde-9032-c51f74505435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Test Accuracy: 0.6994\n",
            "Final Test F1 Score: 0.6935512125268926\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_model(\"fasttext_model.bin\")"
      ],
      "metadata": {
        "id": "D2jxCMFBmkCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "id": "3DjcvYxEpz_x",
        "outputId": "763ff010-8a18-43b8-d9e8-d7faa7ae92ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LhpBNL-1z6Gb"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}