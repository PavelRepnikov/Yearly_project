{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7865400e-be2c-4dff-84a2-8ff64c5a3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\q\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch import nn, optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizerFast\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1815768-c136-49c4-80f7-d332831ff983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/q/Desktop/jupyter/preprocessed_text_and_tag.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5045041-9896-4942-976b-b97f8e2d87b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>most_popular_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>глава аджария аслан абашидзе принять решение у...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>июль российский железный дорога начать продава...</td>\n",
       "      <td>Общество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>использование биткойнов оплата товар услуга да...</td>\n",
       "      <td>Финансы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>число официально подтвердить случай заражение ...</td>\n",
       "      <td>Общество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>президент россия владимир путин телефон обсуди...</td>\n",
       "      <td>Политика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271186</th>\n",
       "      <td>облачная прояснениями погода ожидаться петербу...</td>\n",
       "      <td>Культура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271187</th>\n",
       "      <td>медиапросторам разойтись видео задержание нача...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271188</th>\n",
       "      <td>польский сторона граница украина застрять выех...</td>\n",
       "      <td>Украина</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271189</th>\n",
       "      <td>президент россия владимир путин следующий неде...</td>\n",
       "      <td>Митинг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271190</th>\n",
       "      <td>новый год россия расти продажа сладость традиц...</td>\n",
       "      <td>Погода</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1271191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            processed_text most_popular_tag\n",
       "0        глава аджария аслан абашидзе принять решение у...              Мир\n",
       "1        июль российский железный дорога начать продава...         Общество\n",
       "2        использование биткойнов оплата товар услуга да...          Финансы\n",
       "3        число официально подтвердить случай заражение ...         Общество\n",
       "4        президент россия владимир путин телефон обсуди...         Политика\n",
       "...                                                    ...              ...\n",
       "1271186  облачная прояснениями погода ожидаться петербу...         Культура\n",
       "1271187  медиапросторам разойтись видео задержание нача...           Россия\n",
       "1271188  польский сторона граница украина застрять выех...          Украина\n",
       "1271189  президент россия владимир путин следующий неде...           Митинг\n",
       "1271190  новый год россия расти продажа сладость традиц...           Погода\n",
       "\n",
       "[1271191 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dfb2f69-d266-4cf8-8907-d588a8f7fac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем оригинальный столбец most_popular_tag для последующего сравнения\n",
    "original_most_popular_tag = df['most_popular_tag']\n",
    "\n",
    "# Преобразуем категориальные метки в числовой формат\n",
    "label_encoder = LabelEncoder()\n",
    "df['most_popular_tag'] = label_encoder.fit_transform(df['most_popular_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59a628b8-7b32-4a10-b41e-ff5dd3f474cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбиваем данные на обучающий и тестовый наборы\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['processed_text'], df['most_popular_tag'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0445be54-350f-4f5f-bec1-879401e6e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем TF-IDF векторизатор и преобразуем текст в TF-IDF представление\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Преобразуем данные в numpy arrays и затем в тензоры PyTorch\n",
    "X_train_tfidf = torch.tensor(X_train_tfidf.toarray(), dtype=torch.float32)\n",
    "X_test_tfidf = torch.tensor(X_test_tfidf.toarray(), dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Создаем DataLoader для более удобной обработки данных\n",
    "train_dataset = TensorDataset(X_train_tfidf, y_train)\n",
    "test_dataset = TensorDataset(X_test_tfidf, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bc0a61c-6bcc-43dd-92f0-fd98d7c9f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(ComplexNeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 4096)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(4096, 2048)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc3 = nn.Linear(2048, 2048)\n",
    "        self.dropout3 = nn.Dropout(0.3)\n",
    "        self.fc4 = nn.Linear(2048, 1024)\n",
    "        self.dropout4 = nn.Dropout(0.3)\n",
    "        self.fc5 = nn.Linear(1024, 1024)\n",
    "        self.dropout5 = nn.Dropout(0.3)\n",
    "        self.fc6 = nn.Linear(1024, 512)\n",
    "        self.dropout6 = nn.Dropout(0.3)\n",
    "        self.fc7 = nn.Linear(512, 512)\n",
    "        self.dropout7 = nn.Dropout(0.3)\n",
    "        self.fc8 = nn.Linear(512, 256)\n",
    "        self.dropout8 = nn.Dropout(0.3)\n",
    "        self.fc9 = nn.Linear(256, 256)\n",
    "        self.dropout9 = nn.Dropout(0.3)\n",
    "        self.fc10 = nn.Linear(256, 128)\n",
    "        self.dropout10 = nn.Dropout(0.3)\n",
    "        self.fc11 = nn.Linear(128, 128)\n",
    "        self.dropout11 = nn.Dropout(0.3)\n",
    "        self.fc12 = nn.Linear(128, 64)\n",
    "        self.dropout12 = nn.Dropout(0.3)\n",
    "        self.fc13 = nn.Linear(64, 64)\n",
    "        self.dropout13 = nn.Dropout(0.3)\n",
    "        self.fc14 = nn.Linear(64, 32)\n",
    "        self.dropout14 = nn.Dropout(0.3)\n",
    "        self.fc15 = nn.Linear(32, 32)\n",
    "        self.dropout15 = nn.Dropout(0.3)\n",
    "        self.fc16 = nn.Linear(32, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout4(x)\n",
    "        x = torch.relu(self.fc5(x))\n",
    "        x = self.dropout5(x)\n",
    "        x = torch.relu(self.fc6(x))\n",
    "        x = self.dropout6(x)\n",
    "        x = torch.relu(self.fc7(x))\n",
    "        x = self.dropout7(x)\n",
    "        x = torch.relu(self.fc8(x))\n",
    "        x = self.dropout8(x)\n",
    "        x = torch.relu(self.fc9(x))\n",
    "        x = self.dropout9(x)\n",
    "        x = torch.relu(self.fc10(x))\n",
    "        x = self.dropout10(x)\n",
    "        x = torch.relu(self.fc11(x))\n",
    "        x = self.dropout11(x)\n",
    "        x = torch.relu(self.fc12(x))\n",
    "        x = self.dropout12(x)\n",
    "        x = torch.relu(self.fc13(x))\n",
    "        x = self.dropout13(x)\n",
    "        x = torch.relu(self.fc14(x))\n",
    "        x = self.dropout14(x)\n",
    "        x = torch.relu(self.fc15(x))\n",
    "        x = self.dropout15(x)\n",
    "        x = self.fc16(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afd6e7a7-2469-4f2a-a44c-39e4f14d08e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем устройство (GPU если доступен, иначе CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0b5bb6-5ab1-4401-8542-7b9c0cbe428c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем модель\n",
    "model = ComplexNeuralNetwork(input_dim=X_train_tfidf.shape[1], num_classes=len(label_encoder.classes_)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a352732d-39ca-4396-92b4-28b1dd48a893",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af0a8fb-11a3-40cc-94fd-3be595fcc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для вычисления точности\n",
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(X_batch)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "    return accuracy_score(all_labels, all_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e3d2c08-6b50-48f7-b648-a909ce257acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:28<00:00, 96.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2003, Test Accuracy: 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.19it/s]\n",
      "Epoch 3/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.62it/s]\n",
      "Epoch 4/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:24<00:00, 97.82it/s]\n",
      "Epoch 5/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:28<00:00, 96.82it/s]\n",
      "Epoch 6/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.54it/s]\n",
      "Epoch 7/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.65it/s]\n",
      "Epoch 8/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.30it/s]\n",
      "Epoch 9/50: 100%|████████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.43it/s]\n",
      "Epoch 10/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2003, Test Accuracy: 0.1995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.68it/s]\n",
      "Epoch 12/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.46it/s]\n",
      "Epoch 13/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.45it/s]\n",
      "Epoch 14/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.63it/s]\n",
      "Epoch 15/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.62it/s]\n",
      "Epoch 16/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.45it/s]\n",
      "Epoch 17/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.38it/s]\n",
      "Epoch 18/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:25<00:00, 97.65it/s]\n",
      "Epoch 19/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:26<00:00, 97.26it/s]\n",
      "Epoch 20/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:29<00:00, 96.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2150, Test Accuracy: 0.2123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:58<00:00, 106.32it/s]\n",
      "Epoch 22/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:58<00:00, 106.52it/s]\n",
      "Epoch 23/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:58<00:00, 106.51it/s]\n",
      "Epoch 24/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:58<00:00, 106.41it/s]\n",
      "Epoch 25/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:58<00:00, 106.63it/s]\n",
      "Epoch 26/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:11<00:00, 102.16it/s]\n",
      "Epoch 27/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:18<00:00, 99.66it/s]\n",
      "Epoch 28/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.14it/s]\n",
      "Epoch 29/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:13<00:00, 101.48it/s]\n",
      "Epoch 30/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:59<00:00, 106.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2287, Test Accuracy: 0.2181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 99.98it/s]\n",
      "Epoch 32/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.07it/s]\n",
      "Epoch 33/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.18it/s]\n",
      "Epoch 34/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.17it/s]\n",
      "Epoch 35/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:16<00:00, 100.37it/s]\n",
      "Epoch 36/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:16<00:00, 100.28it/s]\n",
      "Epoch 37/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:16<00:00, 100.39it/s]\n",
      "Epoch 38/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.18it/s]\n",
      "Epoch 39/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.21it/s]\n",
      "Epoch 40/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:17<00:00, 100.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2357, Test Accuracy: 0.2180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [05:16<00:00, 100.28it/s]\n",
      "Epoch 42/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:20<00:00, 99.05it/s]\n",
      "Epoch 43/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [05:19<00:00, 99.34it/s]\n",
      "Epoch 44/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [06:27<00:00, 81.94it/s]\n",
      "Epoch 45/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [09:10<00:00, 57.70it/s]\n",
      "Epoch 46/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [10:02<00:00, 52.71it/s]\n",
      "Epoch 47/50: 100%|███████████████████████████████████████████████████████████████| 31780/31780 [08:52<00:00, 59.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2401, Test Accuracy: 0.2187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:57<00:00, 106.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2413, Test Accuracy: 0.2193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:57<00:00, 106.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2412, Test Accuracy: 0.2188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/50: 100%|██████████████████████████████████████████████████████████████| 31780/31780 [04:57<00:00, 106.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 31780, Train Accuracy: 0.2427, Test Accuracy: 0.2187\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "log_interval = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (X_batch, y_batch) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')):\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if ((epoch + 1) % log_interval == 0) or (epoch > 45) or (epoch == 0):\n",
    "        train_accuracy = calculate_accuracy(model, train_loader, device)\n",
    "        test_accuracy = calculate_accuracy(model, test_loader, device)\n",
    "        print(f'Step {batch_idx+1}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5228a0ba-471f-4241-be29-d8f1ec6a9775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Complete!\n",
      "\n",
      "Final Epoch Metrics:\n",
      "Final Train Loss: 2.453290281388053\n",
      "Final Train Accuracy: 0.24270073710460277\n",
      "Final Train F1 Score: 0.1218994844349302\n",
      "Final Validation Loss: 3.0378237617173385\n",
      "Final Validation Accuracy: 0.21866432766019375\n",
      "Final Validation F1 Score: 0.10074505246931734\n"
     ]
    }
   ],
   "source": [
    "def move_to_device(data, target, device):\n",
    "    return data.to(device), target.to(device)\n",
    "    \n",
    "model.eval()\n",
    "final_train_loss = 0\n",
    "final_train_preds = []\n",
    "final_train_labels = []\n",
    "final_val_loss = 0\n",
    "final_val_preds = []\n",
    "final_val_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = move_to_device(X_batch, y_batch, device)\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        final_train_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        final_train_preds.extend(preds.cpu().numpy())\n",
    "        final_train_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "final_train_loss /= len(train_loader)\n",
    "final_train_accuracy = accuracy_score(final_train_labels, final_train_preds)\n",
    "final_train_f1 = f1_score(final_train_labels, final_train_preds, average='weighted')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = move_to_device(X_batch, y_batch, device)\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        final_val_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        final_val_preds.extend(preds.cpu().numpy())\n",
    "        final_val_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "final_val_loss /= len(test_loader)\n",
    "final_val_accuracy = accuracy_score(final_val_labels, final_val_preds)\n",
    "final_val_f1 = f1_score(final_val_labels, final_val_preds, average='weighted')\n",
    "\n",
    "\n",
    "print(\"\\nTraining Complete!\")\n",
    "print(\"\\nFinal Epoch Metrics:\")\n",
    "print(f\"Final Train Loss: {final_train_loss}\")\n",
    "print(f\"Final Train Accuracy: {final_train_accuracy}\")\n",
    "print(f\"Final Train F1 Score: {final_train_f1}\")\n",
    "print(f\"Final Validation Loss: {final_val_loss}\")\n",
    "print(f\"Final Validation Accuracy: {final_val_accuracy}\")\n",
    "print(f\"Final Validation F1 Score: {final_val_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8225957a-81b6-4e8d-917f-d27fb1384673",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
