{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2661d037-07f0-406e-a8d4-1ddfabac4df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cfded68-b4ca-43a1-b384-3d55b6dd59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('C:/Users/q/Desktop/jupyter/preprocessed_text_50000.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51fb7da-99bd-48cc-8c67-f8cc87ca193e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_texts</th>\n",
       "      <th>most_popular_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>компания zynga game network разработать игра f...</td>\n",
       "      <td>Интернет и СМИ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>учёный обнаружить остров борнео десяток новый ...</td>\n",
       "      <td>Наука и техника</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>турция израиль собираться конец год подписать ...</td>\n",
       "      <td>Экономика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>постоянный представитель россия евросоюз ес вл...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>спикер еврокомиссия петер стано дать комментар...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>депутат государственный дума вторник октябрь п...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>новохопёрский район воронежский область сотруд...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>министр энергетика рф александр новак надеятьс...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>стилист назвать кудрявый причёска главный трен...</td>\n",
       "      <td>Ценности</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>премьер министр италия сильвио берлускони фото...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         processed_texts most_popular_tag\n",
       "0      компания zynga game network разработать игра f...   Интернет и СМИ\n",
       "1      учёный обнаружить остров борнео десяток новый ...  Наука и техника\n",
       "2      турция израиль собираться конец год подписать ...        Экономика\n",
       "3      постоянный представитель россия евросоюз ес вл...              Мир\n",
       "4      спикер еврокомиссия петер стано дать комментар...           Россия\n",
       "...                                                  ...              ...\n",
       "49995  депутат государственный дума вторник октябрь п...           Россия\n",
       "49996  новохопёрский район воронежский область сотруд...           Россия\n",
       "49997  министр энергетика рф александр новак надеятьс...           Россия\n",
       "49998  стилист назвать кудрявый причёска главный трен...         Ценности\n",
       "49999  премьер министр италия сильвио берлускони фото...              Мир\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1d3df61-2aec-4539-90eb-8e37290af882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Настройка устройства (CPU/GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77d3ab2e-90bf-434c-b5e1-ee95a5f34bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['processed_texts'].tolist()\n",
    "labels = df['most_popular_tag'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50f4946-daea-4324-acbb-d5f54efc2fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование строковых меток в числовые\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a343d66-ed0c-4d51-98ae-5557ecbf1308",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Загрузка предобученного токенизатора RoBERTa\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e248cc7-2596-468b-a1d2-c6db08466237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение класса датасета\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Функция для вычисления метрик\n",
    "def compute_metrics(preds, labels):\n",
    "    preds = torch.argmax(preds, dim=1).cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2e0e449-8586-4078-b5db-81d6273c7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\q\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\transformers\\optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Параметры\n",
    "max_len = 512  # Используемое значение max_len\n",
    "batch_size = 16  # Используемое значение batch_size\n",
    "epochs = 30  # Используемое значение epochs\n",
    "\n",
    "# Подготовка датасета и загрузчиков данных\n",
    "dataset = TextDataset(texts, labels, tokenizer, max_len)\n",
    "\n",
    "# Разделение на тренировочную и тестовую выборки\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Загрузка предобученной модели RoBERTa\n",
    "model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=len(label_encoder.classes_))\n",
    "model = model.to(device)\n",
    "\n",
    "# Определение оптимизатора\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebdc46bb-affd-4323-a3de-4ff07fb912b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:35:57<00:00,  6.62s/it]\n",
      "Validation Epoch 1/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:17<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "Train Loss: 2.6590, Train Accuracy: 0.2550, Train F1: 0.1483\n",
      "Test Loss: 2.4304, Test Accuracy: 0.3458, Test F1: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:36:33<00:00,  6.64s/it]\n",
      "Validation Epoch 2/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:40<00:00,  1.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "Train Loss: 2.3408, Train Accuracy: 0.3714, Train F1: 0.3027\n",
      "Test Loss: 2.1616, Test Accuracy: 0.4278, Test F1: 0.3720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:48:21<00:00,  6.92s/it]\n",
      "Validation Epoch 3/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:21<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "Train Loss: 2.0814, Train Accuracy: 0.4457, Train F1: 0.3978\n",
      "Test Loss: 1.9765, Test Accuracy: 0.4664, Test F1: 0.4141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:39:58<00:00,  6.72s/it]\n",
      "Validation Epoch 4/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:59<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "Train Loss: 1.8733, Train Accuracy: 0.4949, Train F1: 0.4610\n",
      "Test Loss: 1.7837, Test Accuracy: 0.5101, Test F1: 0.4892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:38:10<00:00,  6.68s/it]\n",
      "Validation Epoch 5/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:19<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "Train Loss: 1.6068, Train Accuracy: 0.5624, Train F1: 0.5375\n",
      "Test Loss: 1.6149, Test Accuracy: 0.5522, Test F1: 0.5279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:35:52<00:00,  6.62s/it]\n",
      "Validation Epoch 6/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:16<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "Train Loss: 1.4289, Train Accuracy: 0.6025, Train F1: 0.5817\n",
      "Test Loss: 1.5067, Test Accuracy: 0.5800, Test F1: 0.5569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:34:32<00:00,  6.59s/it]\n",
      "Validation Epoch 7/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:15<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "Train Loss: 1.2802, Train Accuracy: 0.6409, Train F1: 0.6224\n",
      "Test Loss: 1.4439, Test Accuracy: 0.5960, Test F1: 0.5782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [5:26:17<00:00,  7.83s/it]\n",
      "Validation Epoch 8/30: 100%|█████████████████████████████████████████████████████████| 625/625 [12:48<00:00,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "Train Loss: 1.1507, Train Accuracy: 0.6736, Train F1: 0.6569\n",
      "Test Loss: 1.3971, Test Accuracy: 0.6150, Test F1: 0.5977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/30: 100%|███████████████████████████████████████████████████████| 2500/2500 [4:35:40<00:00,  6.62s/it]\n",
      "Validation Epoch 9/30: 100%|█████████████████████████████████████████████████████████| 625/625 [11:36<00:00,  1.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "Train Loss: 1.0462, Train Accuracy: 0.6989, Train F1: 0.6849\n",
      "Test Loss: 1.3894, Test Accuracy: 0.6131, Test F1: 0.5995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/30:   0%|                                                         | 3/2500 [00:27<6:20:39,  9.15s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 27\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m train_preds\u001b[38;5;241m.\u001b[39mextend(logits\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n\u001b[0;32m     29\u001b[0m train_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Обучение и оценка модели\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "\n",
    "    # Обучение\n",
    "    for batch in tqdm(train_dataloader, desc=f'Training Epoch {epoch + 1}/{epochs}'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        # # Отладочная информация\n",
    "        # print(f\"Input_ids size: {input_ids.size()}\")\n",
    "        # print(f\"Attention_mask size: {attention_mask.size()}\")\n",
    "        # print(f\"Labels size: {labels.size()}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_preds.extend(logits.detach().cpu())\n",
    "        train_labels.extend(labels.detach().cpu())\n",
    "\n",
    "    train_accuracy, train_f1 = compute_metrics(torch.stack(train_preds), torch.stack(train_labels))\n",
    "\n",
    "    # Оценка на тестовом наборе\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_preds = []\n",
    "    test_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=f'Validation Epoch {epoch + 1}/{epochs}'):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            test_preds.extend(logits.detach().cpu())\n",
    "            test_labels.extend(labels.detach().cpu())\n",
    "\n",
    "    test_accuracy, test_f1 = compute_metrics(torch.stack(test_preds), torch.stack(test_labels))\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(f\"Train Loss: {train_loss/len(train_dataloader):.4f}, Train Accuracy: {train_accuracy:.4f}, Train F1: {train_f1:.4f}\")\n",
    "    print(f\"Test Loss: {test_loss/len(test_dataloader):.4f}, Test Accuracy: {test_accuracy:.4f}, Test F1: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acf9cf0-0a51-4cf0-a7cc-6c52615c04d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2186dab6-f73c-4712-a28b-2d2b9f588873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель, токенизатор и энкодер меток успешно сохранены.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "# Сохранение модели\n",
    "model_path = 'roberta_model.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Сохранение токенизатора\n",
    "tokenizer_path = 'roberta_tokenizer.pkl'\n",
    "with open(tokenizer_path, 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "# Сохранение энкодера меток\n",
    "label_encoder_path = 'roberta_label_encoder.pkl'\n",
    "with open(label_encoder_path, 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print(\"Модель, токенизатор и энкодер меток успешно сохранены.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de03e574-22c7-447f-aba3-8e24e33f0b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda-gpt",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
