{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84e22b91-d98d-4069-b8bf-2f0645924f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c1312c-729f-47bd-831b-28e409d6e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('C:/Users/q/Desktop/jupyter/preprocessed_text_and_tag.csv', sep=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c2c884-3954-4191-9e74-93162a8ada78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_text</th>\n",
       "      <th>most_popular_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>глава аджария аслан абашидзе принять решение у...</td>\n",
       "      <td>Мир</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>июль российский железный дорога начать продава...</td>\n",
       "      <td>Общество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>использование биткойнов оплата товар услуга да...</td>\n",
       "      <td>Финансы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>число официально подтвердить случай заражение ...</td>\n",
       "      <td>Общество</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>президент россия владимир путин телефон обсуди...</td>\n",
       "      <td>Политика</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271186</th>\n",
       "      <td>облачная прояснениями погода ожидаться петербу...</td>\n",
       "      <td>Культура</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271187</th>\n",
       "      <td>медиапросторам разойтись видео задержание нача...</td>\n",
       "      <td>Россия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271188</th>\n",
       "      <td>польский сторона граница украина застрять выех...</td>\n",
       "      <td>Украина</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271189</th>\n",
       "      <td>президент россия владимир путин следующий неде...</td>\n",
       "      <td>Митинг</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271190</th>\n",
       "      <td>новый год россия расти продажа сладость традиц...</td>\n",
       "      <td>Погода</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1271191 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            processed_text most_popular_tag\n",
       "0        глава аджария аслан абашидзе принять решение у...              Мир\n",
       "1        июль российский железный дорога начать продава...         Общество\n",
       "2        использование биткойнов оплата товар услуга да...          Финансы\n",
       "3        число официально подтвердить случай заражение ...         Общество\n",
       "4        президент россия владимир путин телефон обсуди...         Политика\n",
       "...                                                    ...              ...\n",
       "1271186  облачная прояснениями погода ожидаться петербу...         Культура\n",
       "1271187  медиапросторам разойтись видео задержание нача...           Россия\n",
       "1271188  польский сторона граница украина застрять выех...          Украина\n",
       "1271189  президент россия владимир путин следующий неде...           Митинг\n",
       "1271190  новый год россия расти продажа сладость традиц...           Погода\n",
       "\n",
       "[1271191 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8de167e1-240b-43d7-b9ae-043fd723c58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save original most_popular_tag column for later comparison\n",
    "original_most_popular_tag = df['most_popular_tag']\n",
    "\n",
    "# Encode categorical labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "df['most_popular_tag'] = label_encoder.fit_transform(df['most_popular_tag'])\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['processed_text'], df['most_popular_tag'], test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c569e58e-de73-4c74-a8ab-2abcdb5f5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\q\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XLNet tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c6ac4a-93de-4f7e-863f-805855fba87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "086f7aa7-c3c0-4e6e-87d8-d709a40a3a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for easier data handling\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = TextDataset(X_train.tolist(), y_train.tolist(), tokenizer, MAX_LEN)\n",
    "test_dataset = TextDataset(X_test.tolist(), y_test.tolist(), tokenizer, MAX_LEN)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Set device (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a91966b-d5f4-4e6f-b639-a2d089184abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5ef57a-7974-47bc-a5f2-02ed9cba102e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XLNet model for sequence classification\n",
    "model = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=len(label_encoder.classes_))\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53173fb1-51ea-4031-a0c7-aff0b0815452",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1d70863-6d3d-4db6-b83d-981e041ee4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = FocalLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "834ec663-38e2-4a83-b326-f666fc8730a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 63560/63560 [4:25:45<00:00,  3.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "Train Loss: 2.7221, Train Accuracy: 0.1973, Train F1 Score: 0.0774\n",
      "Validation Loss: 2.7197, Validation Accuracy: 0.1995, Validation F1 Score: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 63560/63560 [4:21:48<00:00,  4.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5\n",
      "Train Loss: 2.7162, Train Accuracy: 0.2002, Train F1 Score: 0.0674\n",
      "Validation Loss: 2.7159, Validation Accuracy: 0.1995, Validation F1 Score: 0.0664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|█████▏                                                                     | 4348/63560 [18:21<4:09:59,  3.95it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 20\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     22\u001b[0m train_preds\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_preds = []\n",
    "    train_labels = []\n",
    "    \n",
    "    for batch in tqdm(train_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        train_preds.extend(preds.cpu().numpy())\n",
    "        train_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_accuracy = accuracy_score(train_labels, train_preds)\n",
    "    train_f1 = f1_score(train_labels, train_preds, average='weighted')\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = criterion(outputs.logits, labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            val_preds.extend(preds.cpu().numpy())\n",
    "            val_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(test_loader)\n",
    "    val_accuracy = accuracy_score(val_labels, val_preds)\n",
    "    val_f1 = f1_score(val_labels, val_preds, average='weighted')\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Train F1 Score: {train_f1:.4f}')\n",
    "    print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}, Validation F1 Score: {val_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3af700-9950-4a38-9a6d-9ac281e0a327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c327543-876e-4da9-997a-6301b6af62fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
