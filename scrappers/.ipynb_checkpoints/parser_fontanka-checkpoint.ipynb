{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba90a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf910bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.fontanka.ru/'\n",
    "# Загружаем страницу по ссылке\n",
    "page = requests.get(url)\n",
    "soup = BeautifulSoup(page.text, 'html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d384caec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем url\n",
    "needed_urls = []\n",
    "for link in soup.find_all('a'):\n",
    "    if link.get('href') != None:\n",
    "        if '2023' in link.get('href'):\n",
    "            needed_urls.append(link.get('href'))\n",
    "            \n",
    "# Преобразуем список needed_urls\n",
    "new_urls = [] \n",
    "\n",
    "for url in needed_urls: \n",
    "    if \"all.comments\" not in url: \n",
    "        if not url.startswith(\"https://www.fontanka.ru\"): \n",
    "            url = \"https://www.fontanka.ru\" + url \n",
    "            new_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "056597c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 114/114 [01:53<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# Выбираем первую ссылку\n",
    "url0 = new_urls[0]\n",
    "\n",
    "# Создаем функцию\n",
    "def GetNews(url0):\n",
    "    if not url0.startswith('http'):  # Проверяем, отсутствует ли протокол\n",
    "        url0 = 'https://www.fontanka.ru' + url0  # Добавляем протокол, если отсутствует\n",
    "\n",
    "    page0 = requests.get(url0)\n",
    "    soup0 = BeautifulSoup(page0.text, 'html')\n",
    "\n",
    "    # Дата\n",
    "    try:\n",
    "        date = soup0.find_all('meta', {'itemprop' : 'datePublished'})[0].get('content') \n",
    "        pattern = re.compile(r\"\\d{4}-\\d{2}-\\d{2}\") \n",
    "        match = pattern.findall(date) \n",
    "        if match: \n",
    "            date = match[0] \n",
    "            date = re.sub(r\"-\", \".\", date) \n",
    "    except: \n",
    "        date = None \n",
    "    # Заголовок\n",
    "    title = soup0.find_all('meta', {'property' : 'og:title'})[0].get('content')\n",
    "\n",
    "    # Теги\n",
    "    tags = []\n",
    "    for i in range(len(soup0.find_all('a', {'class' : 'ANbv'}))):\n",
    "        html = soup0.find_all('a', {'class' : 'ANbv'})[i]\n",
    "        soup = BeautifulSoup(str(html), 'html.parser')\n",
    "        tag_text = soup.a.text\n",
    "        tags.append(tag_text)\n",
    "        \n",
    "    text = soup0.find_all('div', {'class': 'B1ah JNap JNah'})\n",
    "\n",
    "    text = BeautifulSoup(str(text), 'html.parser')\n",
    "    # Извлекаем все элементы <div> с классом \"article__text\"\n",
    "    div_elements = text.find_all('div', class_='B1ah JNap JNah')\n",
    "    # Извлекаем текст из каждого элемента и сохраняем его в список\n",
    "    text_list = [element.get_text() for element in div_elements]\n",
    "    # Объединяем текст в одну строку, разделяя переносами строки\n",
    "    full_text = '\\n'.join(text_list)\n",
    "\n",
    "    return url0, date, title, tags, full_text\n",
    "\n",
    "# Создаем список из кортежей, в которых будут храниться данные по каждой новости\n",
    "news = []\n",
    "\n",
    "for link in tqdm(needed_urls):\n",
    "    res = GetNews(link)\n",
    "    news.append(res)\n",
    "    sleep(random.random())\n",
    "\n",
    "df = pd.DataFrame(news)\n",
    "df.columns = ['url', 'date', 'title', 'tags', 'full_text']\n",
    "\n",
    "df.to_csv('news_fontanka_1911.csv',\n",
    "          index=False,\n",
    "          sep=';',\n",
    "          encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
